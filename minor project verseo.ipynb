{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(txt):\n",
    "    \n",
    "    stpw = ['about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'amongst', 'amoungst', 'amount', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'back', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'call', 'can', 'cannot', 'cant', 'con', 'could', 'couldnt', 'cry', 'describe', 'detail', 'done', 'down', 'due', 'during', 'each', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'had', 'has', 'hasnt', 'have', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'inc', 'indeed', 'interest', 'into', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'off', 'often', 'once', 'one', 'only', 'onto', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'under', 'until', 'upon', 'very', 'via', 'was', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', 'the', 'com']\n",
    "    txt = re.sub(r\"\\n\", \" \", txt)\n",
    "    txt = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"[^a-z ]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\b\\w{1,2}\\b\", \" \",txt)\n",
    "    txt = \" \".join([x for x in txt.split() if x not in stpw])\n",
    "    return txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    df = pd.read_csv(\"data.txt\")\n",
    "    df['comment_text'] = df.comment_text.apply(lambda x : cleantxt(x))\n",
    "    \n",
    "    X = df.iloc[:,1]\n",
    "    y = df.iloc[:,2:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n",
    "\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(decode_error='ignore',stop_words='english')\n",
    "train_tfidf = vect.fit_transform(X_train)\n",
    "val_tfidf = vect.transform(X_val)\n",
    "test_tfidf = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "pred_train = np.zeros((X_train.shape[0],len(col)))\n",
    "pred_test = np.zeros((X_test.shape[0],len(col)))\n",
    "pred_val = np.zeros((X_val.shape[0],len(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dev\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic predicted!\n",
      "severe_toxic predicted!\n",
      "obscene predicted!\n",
      "threat predicted!\n",
      "insult predicted!\n",
      "identity_hate predicted!\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(col):\n",
    "    LogR.fit(train_tfidf, y_train[x])\n",
    "    pred_train[:,i] = LogR.predict_proba(train_tfidf)[:,1]\n",
    "    pred_val[:,i] = LogR.predict_proba(val_tfidf)[:,1]\n",
    "    pred_test[:,i] = LogR.predict_proba(test_tfidf)[:,1]\n",
    "    print(x,\"predicted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC = np.zeros((3,6))\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic Train AUC: 0.9856740292915671 , Val AUC: 0.969288204777488 , Test AUC: 0.9676377412562506\n",
      "severe_toxic Train AUC: 0.992689722913682 , Val AUC: 0.9857203795160635 , Test AUC: 0.981633391904646\n",
      "obscene Train AUC: 0.9939668440125141 , Val AUC: 0.9822841003158724 , Test AUC: 0.987497090155988\n",
      "threat Train AUC: 0.9956640450995974 , Val AUC: 0.9716062449414582 , Test AUC: 0.9817858432405686\n",
      "insult Train AUC: 0.9886224678955288 , Val AUC: 0.9739582964447687 , Test AUC: 0.9757563308948265\n",
      "identity_hate Train AUC: 0.9915038958373484 , Val AUC: 0.9759493696932049 , Test AUC: 0.9650255800032955\n",
      "Average Train AUC: 0.9913535008417061 , Average Val AUC: 0.9764677659481427 , Average Test AUC: 0.9765559962425959\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for i,x in enumerate(col):\n",
    "    auc = np.array([metrics.roc_auc_score(y_train[x], pred_train[:,i]),\n",
    "                    metrics.roc_auc_score(y_val[x], pred_val[:,i]),\n",
    "                    metrics.roc_auc_score(y_test[x], pred_test[:,i])])\n",
    "    print(x,\"Train AUC:\",auc[0],\", Val AUC:\",auc[1],\", Test AUC:\",auc[2])\n",
    "    AUC[:,i] = auc\n",
    "\n",
    "avg_auc = AUC.mean(axis=1)\n",
    "print(\"Average Train AUC:\",avg_auc[0],\", Average Val AUC:\",avg_auc[1],\", Average Test AUC:\",avg_auc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
